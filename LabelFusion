 Installing Cuda 8.0 and nvidia-docker 1.0
 
 # Convert ply to vtp for model
 object.ply should be Ascii (not binary)
 root@cc1c784347ba:~/labelfusion/scripts# directorPython convertPlyToVtp.py ~/labelfusion/data/object-meshes/object.ply
 
 # Commands on directorPython window should be typed instead of copy and paste.
 
 # openni2-camera-lcm doesn't work
 install rgbd_ros_to_lcm (code from https://github.com/MobileManipulation/rgbd_ros_to_lcm), but need to modify 
 CMakeLists.txt and package.xml as implemented here https://github.com/hoangcuongbk80/Generate-LCM-LabelFusion
 Then, install lcm: https://github.com/lcm-proj/lcm/blob/master/docs/content/build-instructions.md
 If get error: 
 lcm-logger: error while loading shared libraries: liblcm.so.1: cannot open shared object file: No such file or directory
 solution: sudo ldconfig
 Then, to record log file:
 Run launch file in catkin
 $ roslaunch rgbd_ros_to_lcm lcm_republisher.launch
 In another terminal, run
 $ lcm-logger
 Log file will be save at ~/
 
 # Folder object-meshes containing object model files must be located at /LabelFusion/data/
 
 # Steps to operate the system:
 $ cd ~/LabelFusion/docker
 $ sudo sh docker_run.sh
 $ cd labelfusion/data/
 $ cd labelfusion/data/
 Note that log file shouldn't have name original_log.lcmlog

# To ignore table segmentation step, we should modify
the function def initializeFields(self) of  the file modules/labelfusion/registration.py 

def initializeFields(self):
        self.visFolder = om.getOrCreateContainer('global registration')


        if self.logFolder is None:
            self.logFolder = "logs/scratch"

        self.pathDict = utils.getFilenames(self.logFolder)
        self.objectAlignmentResults = dict() # stores results of object alignment tool
        self.objectAlignmentTool = None

        # load the above table poly data if it exists
        """ self.aboveTablePolyData = None
        if os.path.isfile(self.pathDict['aboveTablePointcloud']):
            print "loading above table pointcloud"
            polyData = ioUtils.readPolyData(self.pathDict['aboveTablePointcloud'])
            self.aboveTablePolyData = filterUtils.transformPolyData(polyData, self.firstFrameToWorldTransform)
            vis.updatePolyData(self.aboveTablePolyData, 'above table pointcloud', parent=self.visFolder, colorByName='RGB') """

        self.aboveTablePolyData = None
        if os.path.isfile(self.pathDict['reconstruction']):
            print "loading above table pointcloud"
            polyData = ioUtils.readPolyData(self.pathDict['reconstruction'])
            self.aboveTablePolyData = filterUtils.transformPolyData(polyData, self.firstFrameToWorldTransform)
            vis.updatePolyData(self.aboveTablePolyData, 'above table pointcloud', parent=self.visFolder, colorByName='RGB')

        self.storedObjects = dict()
        self.loadStoredObjects()

# If the number of object > 13, you need to change rendertrainingimages.py in LabelFusion/modules/labelfusion/:
    def getColorFromIndex(self, objName):
        objLabel = utils.getObjectLabel(self.objectData, objName)
        #cuong
        #return self.colors[objLabel][:3]
        objLabel = objLabel / 10
        return self.colors[objLabel][:3]

# To modify camrera calibration paprameters
##let change /home/aass/Hoang-Cuong/LabelFusion/scripts/prepareForObjectAlignment.py
#### call ElasticFusion
os.system(path_to_ElasticFusion_executable + " -l ./" + lcmlog_filename + " -cal " + "/root/labelfusion//config/camera_calibration.txt")
## and change /home/aass/Hoang-Cuong/LabelFusion/modules/labelfusion/rendertrainingimages.py
def setCameraInstrinsicsAsus(view):
    #principalX = 320.0
    #principalY = 240.0
    #focalLength = 528.0
    #cuong
    principalX = 319.753235
    principalY = 237.822020
    focalLength = 639.445496
    setCameraIntrinsics(view, principalX, principalY, focalLength)
